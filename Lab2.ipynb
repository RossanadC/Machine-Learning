{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOzPpWKXqi8OE3x67pFBwbK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RossanadC/Machine-Learning/blob/main/Lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import"
      ],
      "metadata": {
        "id": "U7GEtyZg8Rkf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "D7nHSY6_6OTd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Neural Network"
      ],
      "metadata": {
        "id": "bSNoHvxY8b9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define neural network\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.lin1 = nn.Linear(28*28, 512)\n",
        "        self.act1 = nn.ReLU()\n",
        "\n",
        "        self.lin2 = nn.Linear(512, 256)\n",
        "        self.act2 = nn.ReLU()\n",
        "\n",
        "        self.output_layer = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)  # (batch_size, 28, 28) => (batch_size, 28*28)\n",
        "\n",
        "        # first layer (input is x, output is x1)\n",
        "        x1 = self.lin1(x)\n",
        "        x1 = self.act1(x1)\n",
        "\n",
        "        # second layer (input is x1, output is x2)\n",
        "        x2 = self.lin2(x1)\n",
        "        x2 = self.act2(x2)\n",
        "\n",
        "        # third/output layer (input is x2, output is logits)\n",
        "        logits = self.output_layer(x2)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "XWmZldjC8WOx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset"
      ],
      "metadata": {
        "id": "wHPuQU2w8iec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "# preprocessing to apply on each data sample:\n",
        "# 1) convert to tensor\n",
        "# 2) normalize images\n",
        "transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.1307,), std=(0.3081,))  # Normalize a tensor image with mean and standard deviation.\n",
        "        ])\n",
        "\n",
        "# Download train data from open datasets.\n",
        "train_data= datasets.FashionMNIST(root='data', train=True, download=True, transform=transform,)\n",
        "\n",
        "# Download test data from open datsets.\n",
        "test_data=datasets.FashionMNIST(root='data', train=False, download=True, transform=transform,)\n",
        "\n",
        "#Validation data\n",
        "train_data, validation_data = torch.utils.data.random_split(train_data, [0.9, 0.1])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_TadU9rY8myE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataloader"
      ],
      "metadata": {
        "id": "w1nxrRr9Ldvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(train_data[100]))\n",
        "print(len(train_data))\n",
        "print(len(test_data))\n",
        "\n",
        "batch_size = 128  # we define here the batch size: number of samples processed before the model is updated\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True) #, drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False) # , drop_last=False)\n",
        "\n",
        "print(f\"batch size: {batch_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_bThE2xLfTl",
        "outputId": "45291451-ad85-4b84-bca9-8e311b072030"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tuple'>\n",
            "54000\n",
            "10000\n",
            "batch size: 128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "f_CiAlTDPLPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function for training\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()  # model to train mode\n",
        "\n",
        "    # ITERATE DATALOADER: train_loader\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        #  SINGLE OPTIMIZATION STEP IS PERFORMED ON A BATCH!\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        loss = F.cross_entropy(output, target)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 50 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "# test\n",
        "# function for evaluation\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()  # model to eval\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    # ITERATE DATALOADER: test_loader\n",
        "    for data, target in test_loader:\n",
        "        batch_size = data.shape[0]\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
        "\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "\n",
        "        # sanity check\n",
        "        pred = pred.view(batch_size)  # [bs,]\n",
        "        target = target.view(batch_size)  # [bs,]\n",
        "\n",
        "        # compute prediction ok\n",
        "        batch_pred_ok = pred.eq(target).sum().item()\n",
        "        correct += batch_pred_ok\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    num_samples = len(test_loader.dataset)\n",
        "    test_accuracy = correct / num_samples\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "oMr9DI-WPM6y"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')  #Â use gpu, is equivalent to .cuda()\n",
        "\n",
        "# training hyperparameters\n",
        "lr = 0.01\n",
        "num_epochs = 30\n",
        "print(f\"lr: {lr}\")\n",
        "print(f\"batch size: {batch_size}\")\n",
        "print(f\"Num. optimization steps per-epoch: {int(len(train_data)/batch_size)}\")\n",
        "\n",
        "#########\n",
        "# MODEL #\n",
        "#########\n",
        "model = NeuralNetwork(num_classes=10)\n",
        "model = model.to(device)\n",
        "\n",
        "#############\n",
        "# OPTIMIZER #\n",
        "#############\n",
        "parameters_to_optimize = model.parameters()\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=lr, momentum=0.9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGWPyWx9RDes",
        "outputId": "b34cd90e-77d1-47fa-aefa-e26f19bb9046"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lr: 0.01\n",
            "batch size: 128\n",
            "Num. optimization steps per-epoch: 421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "  train(model, device, train_loader, optimizer, epoch)\n",
        "  test(model, device, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqMGoE-PRbL4",
        "outputId": "737956b0-3898-47fd-f1c0-bd6e7bfc4409"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/54000 (0%)]\tLoss: 2.281565\n",
            "Train Epoch: 1 [6400/54000 (12%)]\tLoss: 0.710714\n",
            "Train Epoch: 1 [12800/54000 (24%)]\tLoss: 0.599467\n",
            "Train Epoch: 1 [19200/54000 (36%)]\tLoss: 0.537083\n",
            "Train Epoch: 1 [25600/54000 (47%)]\tLoss: 0.571738\n",
            "Train Epoch: 1 [32000/54000 (59%)]\tLoss: 0.522222\n",
            "Train Epoch: 1 [38400/54000 (71%)]\tLoss: 0.475632\n",
            "Train Epoch: 1 [44800/54000 (83%)]\tLoss: 0.448137\n",
            "Train Epoch: 1 [51200/54000 (95%)]\tLoss: 0.430345\n",
            "\n",
            "Test set: Average loss: 0.4689, Accuracy: 8301/10000 (83%)\n",
            "\n",
            "Train Epoch: 2 [0/54000 (0%)]\tLoss: 0.328852\n",
            "Train Epoch: 2 [6400/54000 (12%)]\tLoss: 0.499056\n",
            "Train Epoch: 2 [12800/54000 (24%)]\tLoss: 0.420875\n",
            "Train Epoch: 2 [19200/54000 (36%)]\tLoss: 0.408436\n",
            "Train Epoch: 2 [25600/54000 (47%)]\tLoss: 0.354287\n",
            "Train Epoch: 2 [32000/54000 (59%)]\tLoss: 0.427765\n",
            "Train Epoch: 2 [38400/54000 (71%)]\tLoss: 0.357318\n",
            "Train Epoch: 2 [44800/54000 (83%)]\tLoss: 0.307996\n",
            "Train Epoch: 2 [51200/54000 (95%)]\tLoss: 0.355012\n",
            "\n",
            "Test set: Average loss: 0.4008, Accuracy: 8541/10000 (85%)\n",
            "\n",
            "Train Epoch: 3 [0/54000 (0%)]\tLoss: 0.330944\n",
            "Train Epoch: 3 [6400/54000 (12%)]\tLoss: 0.306643\n",
            "Train Epoch: 3 [12800/54000 (24%)]\tLoss: 0.391496\n",
            "Train Epoch: 3 [19200/54000 (36%)]\tLoss: 0.322824\n",
            "Train Epoch: 3 [25600/54000 (47%)]\tLoss: 0.295106\n",
            "Train Epoch: 3 [32000/54000 (59%)]\tLoss: 0.397058\n",
            "Train Epoch: 3 [38400/54000 (71%)]\tLoss: 0.337395\n",
            "Train Epoch: 3 [44800/54000 (83%)]\tLoss: 0.295929\n",
            "Train Epoch: 3 [51200/54000 (95%)]\tLoss: 0.317539\n",
            "\n",
            "Test set: Average loss: 0.3739, Accuracy: 8621/10000 (86%)\n",
            "\n",
            "Train Epoch: 4 [0/54000 (0%)]\tLoss: 0.262493\n",
            "Train Epoch: 4 [6400/54000 (12%)]\tLoss: 0.342818\n",
            "Train Epoch: 4 [12800/54000 (24%)]\tLoss: 0.399164\n",
            "Train Epoch: 4 [19200/54000 (36%)]\tLoss: 0.441236\n",
            "Train Epoch: 4 [25600/54000 (47%)]\tLoss: 0.338858\n",
            "Train Epoch: 4 [32000/54000 (59%)]\tLoss: 0.278641\n",
            "Train Epoch: 4 [38400/54000 (71%)]\tLoss: 0.292563\n",
            "Train Epoch: 4 [44800/54000 (83%)]\tLoss: 0.296508\n",
            "Train Epoch: 4 [51200/54000 (95%)]\tLoss: 0.229818\n",
            "\n",
            "Test set: Average loss: 0.3675, Accuracy: 8627/10000 (86%)\n",
            "\n",
            "Train Epoch: 5 [0/54000 (0%)]\tLoss: 0.331516\n",
            "Train Epoch: 5 [6400/54000 (12%)]\tLoss: 0.274571\n",
            "Train Epoch: 5 [12800/54000 (24%)]\tLoss: 0.300704\n",
            "Train Epoch: 5 [19200/54000 (36%)]\tLoss: 0.260979\n",
            "Train Epoch: 5 [25600/54000 (47%)]\tLoss: 0.367626\n",
            "Train Epoch: 5 [32000/54000 (59%)]\tLoss: 0.284712\n",
            "Train Epoch: 5 [38400/54000 (71%)]\tLoss: 0.392611\n",
            "Train Epoch: 5 [44800/54000 (83%)]\tLoss: 0.354709\n",
            "Train Epoch: 5 [51200/54000 (95%)]\tLoss: 0.402093\n",
            "\n",
            "Test set: Average loss: 0.3471, Accuracy: 8741/10000 (87%)\n",
            "\n",
            "Train Epoch: 6 [0/54000 (0%)]\tLoss: 0.185368\n",
            "Train Epoch: 6 [6400/54000 (12%)]\tLoss: 0.357179\n",
            "Train Epoch: 6 [12800/54000 (24%)]\tLoss: 0.199166\n",
            "Train Epoch: 6 [19200/54000 (36%)]\tLoss: 0.253133\n",
            "Train Epoch: 6 [25600/54000 (47%)]\tLoss: 0.284213\n",
            "Train Epoch: 6 [32000/54000 (59%)]\tLoss: 0.168817\n",
            "Train Epoch: 6 [38400/54000 (71%)]\tLoss: 0.373432\n",
            "Train Epoch: 6 [44800/54000 (83%)]\tLoss: 0.300334\n",
            "Train Epoch: 6 [51200/54000 (95%)]\tLoss: 0.253873\n",
            "\n",
            "Test set: Average loss: 0.3347, Accuracy: 8773/10000 (88%)\n",
            "\n",
            "Train Epoch: 7 [0/54000 (0%)]\tLoss: 0.224712\n",
            "Train Epoch: 7 [6400/54000 (12%)]\tLoss: 0.275635\n",
            "Train Epoch: 7 [12800/54000 (24%)]\tLoss: 0.221796\n",
            "Train Epoch: 7 [19200/54000 (36%)]\tLoss: 0.286244\n",
            "Train Epoch: 7 [25600/54000 (47%)]\tLoss: 0.270215\n",
            "Train Epoch: 7 [32000/54000 (59%)]\tLoss: 0.230526\n",
            "Train Epoch: 7 [38400/54000 (71%)]\tLoss: 0.330014\n",
            "Train Epoch: 7 [44800/54000 (83%)]\tLoss: 0.141612\n",
            "Train Epoch: 7 [51200/54000 (95%)]\tLoss: 0.197412\n",
            "\n",
            "Test set: Average loss: 0.3340, Accuracy: 8764/10000 (88%)\n",
            "\n",
            "Train Epoch: 8 [0/54000 (0%)]\tLoss: 0.352294\n",
            "Train Epoch: 8 [6400/54000 (12%)]\tLoss: 0.339535\n",
            "Train Epoch: 8 [12800/54000 (24%)]\tLoss: 0.289223\n",
            "Train Epoch: 8 [19200/54000 (36%)]\tLoss: 0.221311\n",
            "Train Epoch: 8 [25600/54000 (47%)]\tLoss: 0.199170\n",
            "Train Epoch: 8 [32000/54000 (59%)]\tLoss: 0.331534\n",
            "Train Epoch: 8 [38400/54000 (71%)]\tLoss: 0.316883\n",
            "Train Epoch: 8 [44800/54000 (83%)]\tLoss: 0.408340\n",
            "Train Epoch: 8 [51200/54000 (95%)]\tLoss: 0.305699\n",
            "\n",
            "Test set: Average loss: 0.3473, Accuracy: 8711/10000 (87%)\n",
            "\n",
            "Train Epoch: 9 [0/54000 (0%)]\tLoss: 0.158380\n",
            "Train Epoch: 9 [6400/54000 (12%)]\tLoss: 0.226380\n",
            "Train Epoch: 9 [12800/54000 (24%)]\tLoss: 0.227930\n",
            "Train Epoch: 9 [19200/54000 (36%)]\tLoss: 0.287538\n",
            "Train Epoch: 9 [25600/54000 (47%)]\tLoss: 0.278913\n",
            "Train Epoch: 9 [32000/54000 (59%)]\tLoss: 0.183567\n",
            "Train Epoch: 9 [38400/54000 (71%)]\tLoss: 0.196399\n",
            "Train Epoch: 9 [44800/54000 (83%)]\tLoss: 0.223730\n",
            "Train Epoch: 9 [51200/54000 (95%)]\tLoss: 0.401647\n",
            "\n",
            "Test set: Average loss: 0.3302, Accuracy: 8805/10000 (88%)\n",
            "\n",
            "Train Epoch: 10 [0/54000 (0%)]\tLoss: 0.198552\n",
            "Train Epoch: 10 [6400/54000 (12%)]\tLoss: 0.217358\n",
            "Train Epoch: 10 [12800/54000 (24%)]\tLoss: 0.193916\n",
            "Train Epoch: 10 [19200/54000 (36%)]\tLoss: 0.249658\n",
            "Train Epoch: 10 [25600/54000 (47%)]\tLoss: 0.270404\n",
            "Train Epoch: 10 [32000/54000 (59%)]\tLoss: 0.263897\n",
            "Train Epoch: 10 [38400/54000 (71%)]\tLoss: 0.291431\n",
            "Train Epoch: 10 [44800/54000 (83%)]\tLoss: 0.317995\n",
            "Train Epoch: 10 [51200/54000 (95%)]\tLoss: 0.237793\n",
            "\n",
            "Test set: Average loss: 0.3155, Accuracy: 8892/10000 (89%)\n",
            "\n",
            "Train Epoch: 11 [0/54000 (0%)]\tLoss: 0.201580\n",
            "Train Epoch: 11 [6400/54000 (12%)]\tLoss: 0.192996\n",
            "Train Epoch: 11 [12800/54000 (24%)]\tLoss: 0.272509\n",
            "Train Epoch: 11 [19200/54000 (36%)]\tLoss: 0.233097\n",
            "Train Epoch: 11 [25600/54000 (47%)]\tLoss: 0.238868\n",
            "Train Epoch: 11 [32000/54000 (59%)]\tLoss: 0.200667\n",
            "Train Epoch: 11 [38400/54000 (71%)]\tLoss: 0.173725\n",
            "Train Epoch: 11 [44800/54000 (83%)]\tLoss: 0.229500\n",
            "Train Epoch: 11 [51200/54000 (95%)]\tLoss: 0.166294\n",
            "\n",
            "Test set: Average loss: 0.3364, Accuracy: 8808/10000 (88%)\n",
            "\n",
            "Train Epoch: 12 [0/54000 (0%)]\tLoss: 0.282339\n",
            "Train Epoch: 12 [6400/54000 (12%)]\tLoss: 0.191856\n",
            "Train Epoch: 12 [12800/54000 (24%)]\tLoss: 0.124856\n",
            "Train Epoch: 12 [19200/54000 (36%)]\tLoss: 0.204129\n",
            "Train Epoch: 12 [25600/54000 (47%)]\tLoss: 0.175982\n",
            "Train Epoch: 12 [32000/54000 (59%)]\tLoss: 0.249484\n",
            "Train Epoch: 12 [38400/54000 (71%)]\tLoss: 0.205098\n",
            "Train Epoch: 12 [44800/54000 (83%)]\tLoss: 0.198100\n",
            "Train Epoch: 12 [51200/54000 (95%)]\tLoss: 0.243709\n",
            "\n",
            "Test set: Average loss: 0.3138, Accuracy: 8887/10000 (89%)\n",
            "\n",
            "Train Epoch: 13 [0/54000 (0%)]\tLoss: 0.186583\n",
            "Train Epoch: 13 [6400/54000 (12%)]\tLoss: 0.179467\n",
            "Train Epoch: 13 [12800/54000 (24%)]\tLoss: 0.230329\n",
            "Train Epoch: 13 [19200/54000 (36%)]\tLoss: 0.115403\n",
            "Train Epoch: 13 [25600/54000 (47%)]\tLoss: 0.183274\n",
            "Train Epoch: 13 [32000/54000 (59%)]\tLoss: 0.226127\n",
            "Train Epoch: 13 [38400/54000 (71%)]\tLoss: 0.247762\n",
            "Train Epoch: 13 [44800/54000 (83%)]\tLoss: 0.177923\n",
            "Train Epoch: 13 [51200/54000 (95%)]\tLoss: 0.186386\n",
            "\n",
            "Test set: Average loss: 0.3252, Accuracy: 8886/10000 (89%)\n",
            "\n",
            "Train Epoch: 14 [0/54000 (0%)]\tLoss: 0.177221\n",
            "Train Epoch: 14 [6400/54000 (12%)]\tLoss: 0.220597\n",
            "Train Epoch: 14 [12800/54000 (24%)]\tLoss: 0.189632\n",
            "Train Epoch: 14 [19200/54000 (36%)]\tLoss: 0.352594\n",
            "Train Epoch: 14 [25600/54000 (47%)]\tLoss: 0.117166\n",
            "Train Epoch: 14 [32000/54000 (59%)]\tLoss: 0.219799\n",
            "Train Epoch: 14 [38400/54000 (71%)]\tLoss: 0.193959\n",
            "Train Epoch: 14 [44800/54000 (83%)]\tLoss: 0.198620\n",
            "Train Epoch: 14 [51200/54000 (95%)]\tLoss: 0.149773\n",
            "\n",
            "Test set: Average loss: 0.3268, Accuracy: 8833/10000 (88%)\n",
            "\n",
            "Train Epoch: 15 [0/54000 (0%)]\tLoss: 0.178751\n",
            "Train Epoch: 15 [6400/54000 (12%)]\tLoss: 0.183583\n",
            "Train Epoch: 15 [12800/54000 (24%)]\tLoss: 0.166072\n",
            "Train Epoch: 15 [19200/54000 (36%)]\tLoss: 0.200078\n",
            "Train Epoch: 15 [25600/54000 (47%)]\tLoss: 0.147041\n",
            "Train Epoch: 15 [32000/54000 (59%)]\tLoss: 0.212808\n",
            "Train Epoch: 15 [38400/54000 (71%)]\tLoss: 0.157128\n",
            "Train Epoch: 15 [44800/54000 (83%)]\tLoss: 0.189781\n",
            "Train Epoch: 15 [51200/54000 (95%)]\tLoss: 0.130719\n",
            "\n",
            "Test set: Average loss: 0.3296, Accuracy: 8889/10000 (89%)\n",
            "\n",
            "Train Epoch: 16 [0/54000 (0%)]\tLoss: 0.156337\n",
            "Train Epoch: 16 [6400/54000 (12%)]\tLoss: 0.309167\n",
            "Train Epoch: 16 [12800/54000 (24%)]\tLoss: 0.130948\n",
            "Train Epoch: 16 [19200/54000 (36%)]\tLoss: 0.130978\n",
            "Train Epoch: 16 [25600/54000 (47%)]\tLoss: 0.171170\n",
            "Train Epoch: 16 [32000/54000 (59%)]\tLoss: 0.136100\n",
            "Train Epoch: 16 [38400/54000 (71%)]\tLoss: 0.151561\n",
            "Train Epoch: 16 [44800/54000 (83%)]\tLoss: 0.158583\n",
            "Train Epoch: 16 [51200/54000 (95%)]\tLoss: 0.129898\n",
            "\n",
            "Test set: Average loss: 0.3348, Accuracy: 8868/10000 (89%)\n",
            "\n",
            "Train Epoch: 17 [0/54000 (0%)]\tLoss: 0.234347\n",
            "Train Epoch: 17 [6400/54000 (12%)]\tLoss: 0.133083\n",
            "Train Epoch: 17 [12800/54000 (24%)]\tLoss: 0.134308\n",
            "Train Epoch: 17 [19200/54000 (36%)]\tLoss: 0.185871\n",
            "Train Epoch: 17 [25600/54000 (47%)]\tLoss: 0.155082\n",
            "Train Epoch: 17 [32000/54000 (59%)]\tLoss: 0.100036\n",
            "Train Epoch: 17 [38400/54000 (71%)]\tLoss: 0.149853\n",
            "Train Epoch: 17 [44800/54000 (83%)]\tLoss: 0.199913\n",
            "Train Epoch: 17 [51200/54000 (95%)]\tLoss: 0.125075\n",
            "\n",
            "Test set: Average loss: 0.3263, Accuracy: 8891/10000 (89%)\n",
            "\n",
            "Train Epoch: 18 [0/54000 (0%)]\tLoss: 0.130943\n",
            "Train Epoch: 18 [6400/54000 (12%)]\tLoss: 0.103363\n",
            "Train Epoch: 18 [12800/54000 (24%)]\tLoss: 0.145755\n",
            "Train Epoch: 18 [19200/54000 (36%)]\tLoss: 0.260206\n",
            "Train Epoch: 18 [25600/54000 (47%)]\tLoss: 0.231358\n",
            "Train Epoch: 18 [32000/54000 (59%)]\tLoss: 0.165210\n",
            "Train Epoch: 18 [38400/54000 (71%)]\tLoss: 0.137951\n",
            "Train Epoch: 18 [44800/54000 (83%)]\tLoss: 0.141027\n",
            "Train Epoch: 18 [51200/54000 (95%)]\tLoss: 0.083056\n",
            "\n",
            "Test set: Average loss: 0.3194, Accuracy: 8919/10000 (89%)\n",
            "\n",
            "Train Epoch: 19 [0/54000 (0%)]\tLoss: 0.183770\n",
            "Train Epoch: 19 [6400/54000 (12%)]\tLoss: 0.217288\n",
            "Train Epoch: 19 [12800/54000 (24%)]\tLoss: 0.095142\n",
            "Train Epoch: 19 [19200/54000 (36%)]\tLoss: 0.166686\n",
            "Train Epoch: 19 [25600/54000 (47%)]\tLoss: 0.161650\n",
            "Train Epoch: 19 [32000/54000 (59%)]\tLoss: 0.216589\n",
            "Train Epoch: 19 [38400/54000 (71%)]\tLoss: 0.149119\n",
            "Train Epoch: 19 [44800/54000 (83%)]\tLoss: 0.079834\n",
            "Train Epoch: 19 [51200/54000 (95%)]\tLoss: 0.165365\n",
            "\n",
            "Test set: Average loss: 0.3247, Accuracy: 8897/10000 (89%)\n",
            "\n",
            "Train Epoch: 20 [0/54000 (0%)]\tLoss: 0.123668\n",
            "Train Epoch: 20 [6400/54000 (12%)]\tLoss: 0.217083\n",
            "Train Epoch: 20 [12800/54000 (24%)]\tLoss: 0.211154\n",
            "Train Epoch: 20 [19200/54000 (36%)]\tLoss: 0.189204\n",
            "Train Epoch: 20 [25600/54000 (47%)]\tLoss: 0.159407\n",
            "Train Epoch: 20 [32000/54000 (59%)]\tLoss: 0.130057\n",
            "Train Epoch: 20 [38400/54000 (71%)]\tLoss: 0.152782\n",
            "Train Epoch: 20 [44800/54000 (83%)]\tLoss: 0.130278\n",
            "Train Epoch: 20 [51200/54000 (95%)]\tLoss: 0.206382\n",
            "\n",
            "Test set: Average loss: 0.3394, Accuracy: 8903/10000 (89%)\n",
            "\n",
            "Train Epoch: 21 [0/54000 (0%)]\tLoss: 0.108718\n",
            "Train Epoch: 21 [6400/54000 (12%)]\tLoss: 0.066003\n",
            "Train Epoch: 21 [12800/54000 (24%)]\tLoss: 0.222596\n",
            "Train Epoch: 21 [19200/54000 (36%)]\tLoss: 0.157663\n",
            "Train Epoch: 21 [25600/54000 (47%)]\tLoss: 0.104768\n",
            "Train Epoch: 21 [32000/54000 (59%)]\tLoss: 0.111142\n",
            "Train Epoch: 21 [38400/54000 (71%)]\tLoss: 0.172726\n",
            "Train Epoch: 21 [44800/54000 (83%)]\tLoss: 0.211937\n",
            "Train Epoch: 21 [51200/54000 (95%)]\tLoss: 0.106890\n",
            "\n",
            "Test set: Average loss: 0.3725, Accuracy: 8834/10000 (88%)\n",
            "\n",
            "Train Epoch: 22 [0/54000 (0%)]\tLoss: 0.068671\n",
            "Train Epoch: 22 [6400/54000 (12%)]\tLoss: 0.179103\n",
            "Train Epoch: 22 [12800/54000 (24%)]\tLoss: 0.097996\n",
            "Train Epoch: 22 [19200/54000 (36%)]\tLoss: 0.118123\n",
            "Train Epoch: 22 [25600/54000 (47%)]\tLoss: 0.089265\n",
            "Train Epoch: 22 [32000/54000 (59%)]\tLoss: 0.093969\n",
            "Train Epoch: 22 [38400/54000 (71%)]\tLoss: 0.097847\n",
            "Train Epoch: 22 [44800/54000 (83%)]\tLoss: 0.105385\n",
            "Train Epoch: 22 [51200/54000 (95%)]\tLoss: 0.186477\n",
            "\n",
            "Test set: Average loss: 0.3623, Accuracy: 8877/10000 (89%)\n",
            "\n",
            "Train Epoch: 23 [0/54000 (0%)]\tLoss: 0.225727\n",
            "Train Epoch: 23 [6400/54000 (12%)]\tLoss: 0.200080\n",
            "Train Epoch: 23 [12800/54000 (24%)]\tLoss: 0.150404\n",
            "Train Epoch: 23 [19200/54000 (36%)]\tLoss: 0.138959\n",
            "Train Epoch: 23 [25600/54000 (47%)]\tLoss: 0.144729\n",
            "Train Epoch: 23 [32000/54000 (59%)]\tLoss: 0.138257\n",
            "Train Epoch: 23 [38400/54000 (71%)]\tLoss: 0.104396\n",
            "Train Epoch: 23 [44800/54000 (83%)]\tLoss: 0.110810\n",
            "Train Epoch: 23 [51200/54000 (95%)]\tLoss: 0.180788\n",
            "\n",
            "Test set: Average loss: 0.3405, Accuracy: 8948/10000 (89%)\n",
            "\n",
            "Train Epoch: 24 [0/54000 (0%)]\tLoss: 0.081940\n",
            "Train Epoch: 24 [6400/54000 (12%)]\tLoss: 0.114815\n",
            "Train Epoch: 24 [12800/54000 (24%)]\tLoss: 0.175016\n",
            "Train Epoch: 24 [19200/54000 (36%)]\tLoss: 0.225150\n",
            "Train Epoch: 24 [25600/54000 (47%)]\tLoss: 0.122615\n",
            "Train Epoch: 24 [32000/54000 (59%)]\tLoss: 0.126003\n",
            "Train Epoch: 24 [38400/54000 (71%)]\tLoss: 0.107220\n",
            "Train Epoch: 24 [44800/54000 (83%)]\tLoss: 0.106087\n",
            "Train Epoch: 24 [51200/54000 (95%)]\tLoss: 0.100564\n",
            "\n",
            "Test set: Average loss: 0.3451, Accuracy: 8945/10000 (89%)\n",
            "\n",
            "Train Epoch: 25 [0/54000 (0%)]\tLoss: 0.076783\n",
            "Train Epoch: 25 [6400/54000 (12%)]\tLoss: 0.073318\n",
            "Train Epoch: 25 [12800/54000 (24%)]\tLoss: 0.107167\n",
            "Train Epoch: 25 [19200/54000 (36%)]\tLoss: 0.090357\n",
            "Train Epoch: 25 [25600/54000 (47%)]\tLoss: 0.103910\n",
            "Train Epoch: 25 [32000/54000 (59%)]\tLoss: 0.115671\n",
            "Train Epoch: 25 [38400/54000 (71%)]\tLoss: 0.129214\n",
            "Train Epoch: 25 [44800/54000 (83%)]\tLoss: 0.092184\n",
            "Train Epoch: 25 [51200/54000 (95%)]\tLoss: 0.195640\n",
            "\n",
            "Test set: Average loss: 0.3672, Accuracy: 8910/10000 (89%)\n",
            "\n",
            "Train Epoch: 26 [0/54000 (0%)]\tLoss: 0.080067\n",
            "Train Epoch: 26 [6400/54000 (12%)]\tLoss: 0.249319\n",
            "Train Epoch: 26 [12800/54000 (24%)]\tLoss: 0.058127\n",
            "Train Epoch: 26 [19200/54000 (36%)]\tLoss: 0.120732\n",
            "Train Epoch: 26 [25600/54000 (47%)]\tLoss: 0.113072\n",
            "Train Epoch: 26 [32000/54000 (59%)]\tLoss: 0.166305\n",
            "Train Epoch: 26 [38400/54000 (71%)]\tLoss: 0.111635\n",
            "Train Epoch: 26 [44800/54000 (83%)]\tLoss: 0.094507\n",
            "Train Epoch: 26 [51200/54000 (95%)]\tLoss: 0.162959\n",
            "\n",
            "Test set: Average loss: 0.3414, Accuracy: 8932/10000 (89%)\n",
            "\n",
            "Train Epoch: 27 [0/54000 (0%)]\tLoss: 0.196039\n",
            "Train Epoch: 27 [6400/54000 (12%)]\tLoss: 0.099376\n",
            "Train Epoch: 27 [12800/54000 (24%)]\tLoss: 0.097683\n",
            "Train Epoch: 27 [19200/54000 (36%)]\tLoss: 0.058906\n",
            "Train Epoch: 27 [25600/54000 (47%)]\tLoss: 0.081883\n",
            "Train Epoch: 27 [32000/54000 (59%)]\tLoss: 0.186667\n",
            "Train Epoch: 27 [38400/54000 (71%)]\tLoss: 0.128731\n",
            "Train Epoch: 27 [44800/54000 (83%)]\tLoss: 0.106222\n",
            "Train Epoch: 27 [51200/54000 (95%)]\tLoss: 0.090393\n",
            "\n",
            "Test set: Average loss: 0.3539, Accuracy: 8973/10000 (90%)\n",
            "\n",
            "Train Epoch: 28 [0/54000 (0%)]\tLoss: 0.091594\n",
            "Train Epoch: 28 [6400/54000 (12%)]\tLoss: 0.054805\n",
            "Train Epoch: 28 [12800/54000 (24%)]\tLoss: 0.082311\n",
            "Train Epoch: 28 [19200/54000 (36%)]\tLoss: 0.136104\n",
            "Train Epoch: 28 [25600/54000 (47%)]\tLoss: 0.067298\n",
            "Train Epoch: 28 [32000/54000 (59%)]\tLoss: 0.085663\n",
            "Train Epoch: 28 [38400/54000 (71%)]\tLoss: 0.220044\n",
            "Train Epoch: 28 [44800/54000 (83%)]\tLoss: 0.122666\n",
            "Train Epoch: 28 [51200/54000 (95%)]\tLoss: 0.063189\n",
            "\n",
            "Test set: Average loss: 0.3805, Accuracy: 8902/10000 (89%)\n",
            "\n",
            "Train Epoch: 29 [0/54000 (0%)]\tLoss: 0.102588\n",
            "Train Epoch: 29 [6400/54000 (12%)]\tLoss: 0.117806\n",
            "Train Epoch: 29 [12800/54000 (24%)]\tLoss: 0.119489\n",
            "Train Epoch: 29 [19200/54000 (36%)]\tLoss: 0.121107\n",
            "Train Epoch: 29 [25600/54000 (47%)]\tLoss: 0.084563\n",
            "Train Epoch: 29 [32000/54000 (59%)]\tLoss: 0.056286\n",
            "Train Epoch: 29 [38400/54000 (71%)]\tLoss: 0.099346\n",
            "Train Epoch: 29 [44800/54000 (83%)]\tLoss: 0.106427\n",
            "Train Epoch: 29 [51200/54000 (95%)]\tLoss: 0.088587\n",
            "\n",
            "Test set: Average loss: 0.3936, Accuracy: 8929/10000 (89%)\n",
            "\n",
            "Train Epoch: 30 [0/54000 (0%)]\tLoss: 0.089691\n",
            "Train Epoch: 30 [6400/54000 (12%)]\tLoss: 0.088834\n",
            "Train Epoch: 30 [12800/54000 (24%)]\tLoss: 0.087995\n",
            "Train Epoch: 30 [19200/54000 (36%)]\tLoss: 0.069955\n",
            "Train Epoch: 30 [25600/54000 (47%)]\tLoss: 0.116746\n",
            "Train Epoch: 30 [32000/54000 (59%)]\tLoss: 0.155662\n",
            "Train Epoch: 30 [38400/54000 (71%)]\tLoss: 0.105783\n",
            "Train Epoch: 30 [44800/54000 (83%)]\tLoss: 0.062517\n",
            "Train Epoch: 30 [51200/54000 (95%)]\tLoss: 0.120216\n",
            "\n",
            "Test set: Average loss: 0.3918, Accuracy: 8905/10000 (89%)\n",
            "\n",
            "CPU times: user 5min 55s, sys: 839 ms, total: 5min 56s\n",
            "Wall time: 5min 59s\n"
          ]
        }
      ]
    }
  ]
}